{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doodles and notes - nothing important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import network_diffusion as nd\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from misc.utils import extract_basic_stats\n",
    "from misc import net_loader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_diffusion.mln import cbim\n",
    "from network_diffusion.seeding import CBIMSeedselector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cbim.get_toy_network_cbim()\n",
    "mergingIndexThreshold = .05\n",
    "seedNodeAmount = 3\n",
    "\n",
    "seeds = cbim.cbim_seed_selection(\n",
    "    net=net,\n",
    "    merging_idx_threshold=mergingIndexThreshold,\n",
    "    num_seeds=seedNodeAmount,\n",
    ")\n",
    "print(f\"nodes nb: {net.number_of_nodes()}, edges nb: {net.number_of_edges()}\")\n",
    "print(f\"parameters: k: {seedNodeAmount}, Î´: {mergingIndexThreshold}\")\n",
    "print(f\"seeds: {seeds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = cbim.cbim_seed_ranking(\n",
    "    net=nnet[\"work\"],\n",
    "    merging_idx_threshold=0.05,\n",
    "    debug=True\n",
    ")\n",
    "print(f\"Ranking: {ranking}\")\n",
    "\n",
    "nnet.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBIMSeedselector(merging_idx_threshold=mergingIndexThreshold).nodewise(nnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBIMSeedselector(merging_idx_threshold=mergingIndexThreshold).actorwise(nnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from network_diffusion.seeding import degree_discount\n",
    "from network_diffusion.mln import functions, centrality_discount\n",
    "\n",
    "nnet = functions.get_toy_network_cim()\n",
    "# nnet = functions.get_toy_network_piotr()\n",
    "# nnet = kppshell.get_toy_network_kppshell()\n",
    "l = nnet[\"l3\"]\n",
    "\n",
    "nnet = net_loader.get_aucs_network()\n",
    "l = nnet[\"lunch\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "layout = nx.drawing.kamada_kawai_layout(l)\n",
    "options = {\n",
    "    \"font_size\": 12,\n",
    "    \"node_size\": 300,\n",
    "    \"node_color\": \"white\",\n",
    "    \"edgecolors\": \"black\",\n",
    "    \"linewidths\": 1,\n",
    "    \"width\": 1,\n",
    "    \"with_labels\": True,\n",
    "}\n",
    "\n",
    "nx.draw(l, ax=axs, pos=layout, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_discount.neighbourhood_size_discount(nnet, len(l.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__ = nd.MultilayerNetwork.from_nx_layer(l, [\"l2\"])\n",
    "centrality_discount.degree_discount(__, len(nnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_discount.neighbourhood_size_discount(__, len(nnet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K++ Shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_diffusion.mln import functions \n",
    "from network_diffusion.mln import kppshell\n",
    "from misc.net_loader import get_aucs_network, get_ckm_physicians_network\n",
    "nnet = functions.get_toy_network_cim()\n",
    "nnet = kppshell.get_toy_network_kppshell()\n",
    "# nnet = get_ckm_physicians_network()\n",
    "\n",
    "l = nnet[\"l1\"]\n",
    "# nnet.layers\n",
    "# l = nnet[\"advice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "layout = nx.drawing.kamada_kawai_layout(l)\n",
    "options = {\n",
    "    \"font_size\": 12,\n",
    "    \"node_size\": 300,\n",
    "    \"node_color\": \"white\",\n",
    "    \"edgecolors\": \"black\",\n",
    "    \"linewidths\": 1,\n",
    "    \"width\": 1,\n",
    "    \"with_labels\": True,\n",
    "}\n",
    "\n",
    "nx.draw(l, ax=axs, pos=layout, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comms = list(nx.community.label_propagation_communities(l))\n",
    "print(comms)\n",
    "print([len(c) for c in comms])\n",
    "\n",
    "quotas = kppshell.compute_seed_quotas(l, comms, 10)\n",
    "print(quotas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shells = kppshell.kppshell_decomposition(l)\n",
    "shells\n",
    "\n",
    "# one tuple below has a typo\n",
    "# ð¶1 = {(ðµ1, 11, 0), (ðµ2, 5, 1)(ðµ2, 2, 0)(ðµ3, 1, 2), (ðµ3, 7, 2), (ðµ3, 3, 0), (ðµ3, 4, 0)}\n",
    "# ð¶2 = {(ðµ1, 8, 0), (ðµ2, 6, 2), (ðµ2, 9, 0), (ðµ2, 10, 0), (ðµ2, 12, 0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kppshell.kppshell_seed_selection(l, 4), kppshell.kppshell_seed_ranking(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_diffusion.seeding import KPPShellSeedSelector\n",
    "\n",
    "print(nw_ranking := KPPShellSeedSelector().nodewise(nnet))\n",
    "KPPShellSeedSelector().actorwise(nnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print({l_name: len(l_ranking) for l_name, l_ranking in nw_ranking.items()})\n",
    "print({l_name: len(l_graph) for l_name, l_graph in nnet.layers.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_diffusion.seeding import cim\n",
    "from network_diffusion.mln.functions import get_toy_network_cim\n",
    "# nnet = get_toy_network_cim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "\n",
    "layout = nx.drawing.kamada_kawai_layout(nnet[\"l1\"])\n",
    "options = {\n",
    "    \"font_size\": 12,\n",
    "    \"node_size\": 300,\n",
    "    \"node_color\": \"white\",\n",
    "    \"edgecolors\": \"black\",\n",
    "    \"linewidths\": 1,\n",
    "    \"width\": 1,\n",
    "    \"with_labels\": True,\n",
    "}\n",
    "\n",
    "for idx, (l_name, l_graph) in enumerate(nnet.layers.items()):\n",
    "    nx.draw(l_graph, ax=axs[idx], pos=layout, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "print(f\"Layer: l1, ranking: {cim.clique_influence_maximization(nnet['l1'], K, False)}\")\n",
    "print(f\"Layer: l2, ranking: {cim.clique_influence_maximization(nnet['l2'], K, False)}\")\n",
    "print(f\"Layer: l3, ranking: {cim.clique_influence_maximization(nnet['l3'], K, False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cim.CIMSeedSelector().actorwise(net=nnet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example rankings for toy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cbim': {4: 1, 3: 2, 8: 3, 9: 4, 2: 5, 11: 6, 5: 7, 6: 8, 1: 9, 7: 10, 10: 11}, 'cim': {11: 1, 4: 2, 3: 3, 6: 4, 8: 5, 9: 6, 2: 7, 5: 8, 7: 9, 10: 10, 1: 11}, 'deg-c': {4: 1, 5: 2, 2: 3, 9: 4, 3: 5, 6: 6, 10: 7, 11: 8, 7: 9, 8: 10, 1: 11}, 'deg-c-d': {4: 1, 5: 2, 9: 3, 2: 4, 10: 5, 3: 6, 7: 7, 8: 8, 11: 9, 1: 10, 6: 11}, 'k-sh': {3: 1, 4: 2, 2: 3, 11: 4, 5: 5, 8: 6, 9: 7, 6: 8, 10: 9, 7: 10, 1: 11}, 'k-sh-m': {4: 1, 5: 2, 2: 3, 3: 4, 6: 5, 9: 6, 10: 7, 11: 8, 7: 9, 8: 10, 1: 11}, 'kpp-sh': {8: 1, 5: 2, 3: 3, 9: 4, 11: 5, 2: 6, 4: 7, 1: 8, 10: 9, 6: 10, 7: 11}, 'nghb-2s': {2: 1, 6: 2, 9: 3, 11: 4, 4: 5, 3: 6, 1: 7, 5: 8, 7: 9, 10: 10, 8: 11}, 'nghb-1s': {2: 1, 6: 2, 4: 3, 3: 4, 5: 5, 9: 6, 10: 7, 11: 8, 1: 9, 7: 10, 8: 11}, 'nghb-sd': {2: 1, 6: 2, 4: 3, 5: 4, 9: 5, 10: 6, 1: 7, 3: 8, 7: 9, 8: 10, 11: 11}, 'p-rnk': {11: 1, 3: 2, 4: 3, 9: 4, 8: 5, 2: 6, 5: 7, 10: 8, 7: 9, 6: 10, 1: 11}, 'p-rnk-m': {2: 1, 6: 2, 4: 3, 9: 4, 5: 5, 3: 6, 10: 7, 11: 8, 8: 9, 7: 10, 1: 11}, 'v-rnk': {4: 1, 9: 2, 11: 3, 3: 4, 8: 5, 2: 6, 5: 7, 1: 8, 6: 9, 10: 10, 7: 11}, 'v-rnk-m': {2: 1, 6: 2, 10: 3, 9: 4, 4: 5, 5: 6, 8: 7, 7: 8, 3: 9, 1: 10, 11: 11}}\n"
     ]
    }
   ],
   "source": [
    "from network_diffusion.mln.functions import get_toy_network_piotr\n",
    "net =  get_toy_network_piotr()\n",
    "\n",
    "rankings = {}\n",
    "\n",
    "all_selectors = {\n",
    "    \"cbim\": nd.seeding.CBIMSeedselector(merging_idx_threshold=0.1),\n",
    "    \"cim\": nd.seeding.CIMSeedSelector(),\n",
    "    \"deg-c\": nd.seeding.DegreeCentralitySelector(),\n",
    "    \"deg-c-d\": nd.seeding.DegreeCentralityDiscountSelector(),\n",
    "    \"k-sh\": nd.seeding.KShellSeedSelector(),\n",
    "    \"k-sh-m\": nd.seeding.KShellMLNSeedSelector(),\n",
    "    \"kpp-sh\": nd.seeding.KPPShellSeedSelector(),\n",
    "    \"nghb-2s\": nd.seeding.NeighbourhoodSizeSelector(2),\n",
    "    \"nghb-1s\": nd.seeding.NeighbourhoodSizeSelector(1),\n",
    "    \"nghb-sd\": nd.seeding.NeighbourhoodSizeDiscountSelector(),\n",
    "    \"p-rnk\": nd.seeding.PageRankSeedSelector(),\n",
    "    \"p-rnk-m\": nd.seeding.PageRankMLNSeedSelector(),\n",
    "    \"v-rnk\": nd.seeding.VoteRankSeedSelector(),\n",
    "    \"v-rnk-m\": nd.seeding.VoteRankMLNSeedSelector(),\n",
    "}\n",
    "\n",
    "for s_name, ss in all_selectors.items():\n",
    "    _ranking = ss.actorwise(net)\n",
    "    ranking = {actor.actor_id: place for place, actor in enumerate(_ranking, 1)}\n",
    "\n",
    "    if rankings.get(s_name) is None:\n",
    "        rankings[s_name] = {}\n",
    "    rankings[s_name] = ranking\n",
    "\n",
    "print(rankings)\n",
    "ranking_full = pd.DataFrame(rankings).T\n",
    "ranking_full = ranking_full.reindex(sorted(ranking_full.columns), axis=1)\n",
    "ranking_full.to_csv(\"_results/toy_network_rank.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA of networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.net_loader import load_network\n",
    "nets = [\n",
    "    \"arxiv\",\n",
    "    \"aucs\",\n",
    "    \"cannes\",\n",
    "    \"ckm_physicians\",\n",
    "    \"eu_transportation\",\n",
    "    \"eu_trans_1\",\n",
    "    \"lazega\",\n",
    "    \"er1\",\n",
    "    \"er2\",\n",
    "    \"er3\",\n",
    "    \"er5\",\n",
    "    \"sf1\",\n",
    "    \"sf2\",\n",
    "    \"sf3\",\n",
    "    \"sf5\",\n",
    "    \"timik1q2009\",\n",
    "]\n",
    "\n",
    "stats = {}\n",
    "\n",
    "for net in nets:\n",
    "    n = load_network(net)\n",
    "    layers_cnt = len(n.get_layer_names())\n",
    "    actors_cnt = n.get_actors_num()\n",
    "    nodes_cnt = sum(n.get_nodes_num().values())\n",
    "    edges_cnt = sum([len(lg.edges()) for lg in n.layers.values()])\n",
    "    stats[net] = {\"layers\": layers_cnt, \"actors\": actors_cnt, \"nodes\": nodes_cnt, \"edges\": edges_cnt}\n",
    "\n",
    "stats = pd.DataFrame(stats).T\n",
    "stats.to_csv(\"_results/networks_eda.csv\")\n",
    "stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of LTM spread on the toy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial seeds for the process choosen arbitrarly\n",
    "seeds = [net.get_actor(8), net.get_actor(1), net.get_actor(6)]\n",
    "\n",
    "# ranking that has actors 8 and 1 at the beginning and then the rest of actors\n",
    "actors_ranking = [*seeds, *set(net.get_actors()).difference(set(seeds))]\n",
    "seed_selector = nd.seeding.MockyActorSelector(actors_ranking)\n",
    "\n",
    "# precentages of initially active and inactive actors\n",
    "prct_active = len(seeds) / net.get_actors_num() * 100\n",
    "prct_inactive = 100 - prct_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mltm = nd.models.MLTModel(\n",
    "    protocol=\"OR\",\n",
    "    seed_selector=seed_selector,\n",
    "    seeding_budget = (prct_inactive, prct_active),\n",
    "    mi_value=0.3,\n",
    ")\n",
    "\n",
    "# run experiment on a deep copy of the network\n",
    "experiment = nd.MultiSpreading(model=mltm, network=net.copy())\n",
    "logs = experiment.perform_propagation(n_epochs=10, patience=1)\n",
    "\n",
    "logs.report(visualisation=False, path=\".\")\n",
    "diffusion_len, active_actors, _ = extract_basic_stats(\n",
    "    detailed_logs=logs._local_stats, patience=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_len, active_actors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbourhood size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from misc.loader import *\n",
    "from network_diffusion.mln.mlnetwork import MLNetworkActor, MultilayerNetwork\n",
    "\n",
    "ns = nd.mln.functions.neighbourhood_size\n",
    "nsh = nd.mln.functions._ns_helper\n",
    "\n",
    "def ns_old(net: MultilayerNetwork) -> Dict[MLNetworkActor, int]:\n",
    "    \"\"\"Return neighbourhood sizes of all actors from the network.\"\"\"\n",
    "    neighbourhood_sizes: Dict[MLNetworkActor, int] = {}\n",
    "    for actor in net.get_actors():\n",
    "        a_neighbours: Set[Any] = set()\n",
    "        for l_name in actor.layers:\n",
    "            a_neighbours = a_neighbours.union(\n",
    "                set(net.layers[l_name].adj[actor.actor_id].keys())\n",
    "            )\n",
    "        neighbourhood_sizes[actor] = len(a_neighbours)\n",
    "    return neighbourhood_sizes\n",
    "\n",
    "nets = [\n",
    "    net,\n",
    "    get_aucs_network(), \n",
    "    get_ckm_physicians_network(),\n",
    "    get_eu_transportation_network(),\n",
    "    get_lazega_network(),\n",
    "    get_er2_network(),\n",
    "    get_er3_network(),\n",
    "    get_er5_network(),\n",
    "    get_sf2_network(),\n",
    "    get_sf3_network(),\n",
    "    get_sf5_network(),\n",
    "]\n",
    "\n",
    "def ravel_rank(rank):\n",
    "    return {a.actor_id: v for a, v in rank.items()}\n",
    "\n",
    "for n in nets:\n",
    "    print(ravel_rank(ns(net, 1)) == ravel_rank(ns_old(net)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-shell for single layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = nx.Graph()\n",
    "g.add_edges_from(\n",
    "    [(1, 2), (1, 9), (3, 13), (4, 6),\n",
    "    (5, 6), (5, 7), (5, 8), (5, 9),\n",
    "    (5, 10), (5, 11), (5, 12), (10, 12),\n",
    "    (10, 13), (11, 14), (12, 14),\n",
    "    (12, 15), (13, 14), (13, 15),\n",
    "    (13, 17), (14, 15), (15, 16)]\n",
    ")\n",
    "nx.draw(g, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = nx.core.k_shell(g, 2)\n",
    "nx.draw(gg, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nd.MultilayerNetwork.load_mlx(file_path=\"data/aucs.mpx\")\n",
    "fb = net.layers[\"facebook\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = fb.copy()\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3)\n",
    "row = -1\n",
    "col = -1\n",
    "\n",
    "for k in range(9):\n",
    "\n",
    "    row += 1\n",
    "    if row % 3 == 0:\n",
    "        row = 0\n",
    "        col += 1\n",
    "\n",
    "    axis = axes[col][row]\n",
    "    axis.set_title(f\"K={k}\")\n",
    "\n",
    "    ggg = nx.k_shell(gg, k=k)\n",
    "    \n",
    "    nx.draw(ggg, with_labels=True, ax=axis)\n",
    "    print(k, [[node, nx.degree(gg, node)] for node in ggg.nodes()])\n",
    "\n",
    "    if len(list(gg.nodes())) == 0:\n",
    "        break\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(sh:=nx.k_shell(fb), with_labels=True)\n",
    "print(k, [[node, nx.degree(fb, node)] for node in sh.nodes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(fb, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k_shell_list(g: nx.Graph):\n",
    "    ksh_deepest_nodes = set(nx.k_shell(g).nodes())\n",
    "    shell_ranking = {}\n",
    "    k = 0\n",
    "\n",
    "    while True:\n",
    "        ksh_nodes = set(nx.k_shell(g, k=k).nodes())\n",
    "        shell_ranking[k] = ksh_nodes\n",
    "        if ksh_nodes == ksh_deepest_nodes:\n",
    "            break\n",
    "        k += 1\n",
    "    \n",
    "    return shell_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = create_k_shell_list(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(rl)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = [list(rl[k]) for k in sorted(rl)[::-1]]\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lll = [n for cohort in sorted(rl)[::-1] for n in rl[cohort]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lll"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.get_actors_num())\n",
    "for actor in net.get_actors():\n",
    "    print(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = nd.seeding.PageRankSeedSelector()\n",
    "ranking = selector(net, actorwise=True)\n",
    "print([r.actor_id for r in ranking])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.pagerank(net.layers[\"l1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = { 'num6': 6, \"34\": 2, 'num2': 2, 'num4': 4, 'num1': 1, 'num5': 5}\n",
    "sortedDict = sorted(my_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeding_budgets = np.arange(0, 101, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [(a, 100 - a) for a in np.arange(0, 101, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.logspace(-2, 0, num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-shell for multi layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_diffusion.mln.functions import k_shell_mln, degree, neighbourhood_size\n",
    "\n",
    "net ## net from degree centrality\n",
    "degrees = degree(net)\n",
    "sorted(\n",
    "        [*degrees.keys()],\n",
    "        key=lambda x: degree(net)[x],\n",
    "        reverse=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_size(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net.layers[\"l1\"].nodes[5][\"status\"] = \"test\"\n",
    "k_net = k_shell_mln(net)\n",
    "print(degree(k_net))\n",
    "print(k_net.layers[\"l1\"].nodes[5][\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksh_deepest_nodes = set(k_shell_mln(net).get_actors())\n",
    "shell_ranking = {}\n",
    "k = 0\n",
    "\n",
    "# iterate until deepest shell is achieved\n",
    "while True:\n",
    "\n",
    "    # compute k-shell cohort\n",
    "    ksh_nodes = k_shell_mln(net, k=k).get_actors()\n",
    "\n",
    "    # sort it according to degree in the graph\n",
    "    shell_ranking[k] = sorted(\n",
    "        ksh_nodes,\n",
    "        key=lambda x: degree(net)[x],\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    # if the deepest shell is reached breake, othrwise increase k\n",
    "    if set(ksh_nodes) == ksh_deepest_nodes:\n",
    "        break\n",
    "    k += 1\n",
    "\n",
    "shell_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksh_selector = nd.seeding.KShellSeedSelector()\n",
    "ksh_selector.actorwise(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank for MLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_net = net.layers[\"l1\"]\n",
    "nx.pagerank(l1_net)\n",
    "\n",
    "squeezed_net = nd.mln.functions.squeeze_by_neighbourhood(net)\n",
    "raw_dict = nx.pagerank(squeezed_net)\n",
    "sorted_dict = sorted(\n",
    "    raw_dict, key=lambda x: raw_dict[x], reverse=True\n",
    ")\n",
    "\n",
    "# for k, v in raw_dict.items():\n",
    "#     print(k.actor_id, v)\n",
    "print(sorted_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.seeding.PageRankMLNSeedSelector().actorwise(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import get_sf2_network\n",
    "sf2 = get_sf2_network()\n",
    "net_len = sf2.get_actors_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_len = len(nd.seeding.PageRankMLNSeedSelector().actorwise(sf2))\n",
    "sqnet_len = len(nd.mln.functions.squeeze_by_neighbourhood(sf2))\n",
    "print(net_len, sqnet_len, rank_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voterank for MLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_diffusion.mln.functions import voterank_actorwise\n",
    "from network_diffusion.mln.actor import MLNetworkActor\n",
    "\n",
    "# [[*l_graph.edges()] for l_graph in net.layers.values()]\n",
    "\n",
    "for _, nbr in net.layers[\"l1\"].edges(1):\n",
    "    print(_, nbr)\n",
    "    # vote_rank[nbr][1] -= 1 / avgDegree\n",
    "    # vote_rank[nbr][1] = max(vote_rank[nbr][1], 0)\n",
    "\n",
    "# n2 = nd.MultilayerNetwork.from_nx_layer(net.layers[\"l3\"].copy(), layer_names=[\"A\", \"B\", \"C\"])\n",
    "\n",
    "# net.is_directed()\n",
    "# print(voterank_actorwise(n2))\n",
    "print(voterank_actorwise(net))\n",
    "# print(nx.voterank(n2.layers[\"C\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in net.get_links(10):\n",
    "    print(f\"a: {a.actor_id}, b: {b.actor_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd.seeding.VoteRankMLNSeedSelector().actorwise(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading from .edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ckm_network(path):\n",
    "    df = pd.read_csv(path, names=[\"node_1\", \"node_2\", \"layer\"])\n",
    "    net_dict = {l_name: nx.Graph() for l_name in [*df[\"layer\"].unique()]}\n",
    "    for _, row in df.iterrows():\n",
    "        net_dict[row[\"layer\"]].add_edge(row[\"node_1\"], row[\"node_2\"])\n",
    "    return nd.MultilayerNetwork.load_layers_nx(\n",
    "        layer_names=[*net_dict.keys()], network_list=[*net_dict.values()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckm = \"data/CKM-Physicians-Innovation_4NoNature.edges\"\n",
    "eu_transportation = \"data/EUAirTransportation_multiplex_4NoNature.edges\"\n",
    "lazega = \"data/Lazega-Law-Firm_4NoNatureNoLoops.edges\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_ckm_network(lazega)\n",
    "print(net.get_actors_num())\n",
    "print(_ := net.get_nodes_num(), sum(_.values()), len(set(_.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aucs_network(file_path):\n",
    "    return nd.MultilayerNetwork.load_mlx(file_path)\n",
    "\n",
    "net = get_aucs_network(file_path=\"data/erererererNoLoops.mpx\")\n",
    "print(net.get_actors_num())\n",
    "print(_ := net.get_nodes_num(), sum(_.values()), len(set(_.keys())), sum([l.number_of_edges() for l in net.layers.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical metrics aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = nd.seeding.VoteRankSeedSelector().nodewise(net=net)\n",
    "\n",
    "print(ranking)\n",
    "print({l_name: len(l_graph) for l_name, l_graph in net.layers.items()})\n",
    "\n",
    "aggregated_ranking = nd.seeding.VoteRankSeedSelector().actorwise(net=net)\n",
    "\n",
    "print(aggregated_ranking)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting baseline networks with one layer\n",
    "\n",
    "After analysis we took as SF network: sf5.l3, as ER network: er5.l2 as real \n",
    "network: eu_transportation.KLM. We chose layers by smallest num of connected \n",
    "componenets, smallest density, and longest diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import net_loader\n",
    "networks = [\n",
    "  \"aucs\",\n",
    "  \"ckm_physicians\",\n",
    "  \"eu_transportation\",\n",
    "  \"eu_trans_1\",\n",
    "  \"lazega\",\n",
    "  \"er1\",\n",
    "  \"er2\",\n",
    "  \"er3\",\n",
    "  \"er5\",\n",
    "  \"sf1\",\n",
    "  \"sf2\",\n",
    "  \"sf3\",\n",
    "  \"sf5\",\n",
    "]\n",
    "nets = [(n, net_loader.load_network(n)) for n in networks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for (net_name, net) in nets:\n",
    "    for l_name, l_graph in net.layers.items():\n",
    "        cc = len(list(nx.connected_components(l_graph)))\n",
    "        if cc > 1:\n",
    "            dd = None\n",
    "        else:\n",
    "            dd = nx.diameter(l_graph)\n",
    "        df_list.append(\n",
    "            {\n",
    "                \"net_name\": net_name,\n",
    "                \"l_name\": l_name,\n",
    "                \"connected_components\": cc,\n",
    "                \"nodes\": len(l_graph.nodes()),\n",
    "                \"edges\": len(l_graph.edges()),\n",
    "                \"diameter\": dd,\n",
    "                \"density\": nx.density(l_graph)\n",
    "            }\n",
    "        )\n",
    "\n",
    "df = pd.DataFrame(df_list)\n",
    "df.to_csv(\"net_stats.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm-seeding-mln",
   "language": "python",
   "name": "ltm-seeding-mln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
